\section{General Purpose Service Robot}

%
% MAURICIO @2017
% Short instructions as in 2012 rulebook
%
This test evaluates the abilities of the robot that are required throughout the set of tests in stage I of this and previous years' RuleBooks. In this test the robot has to solve multiple tasks upon request. That is, the test is not incorporated into a (predefined) story and there is neither a predefined order of tasks nor a predefined set of actions. The actions that are to be carried out by the robot are chosen randomly by the referees from a larger set of actions. These actions are organized in three categories with different complexity. Scoring thereby depends on the complexity class.

%
% MAURICIO @2017
% Same focus as in 2012 rulebook. There should be no problem since this is SOLVED
%
\subsection{Focus}
This test particularly focuses on the following aspects:
\begin{itemize}
	\item No predefined order of actions to carry out (to get away from state machine-like behavior programming).
	\item Increased complexity in speech recognition.
	\item Environmental (high-level) reasoning.
	\item Efficient and fast task execution (speed).
\end{itemize}


%
% MAURICIO @2017
% Test has been shorten based in 2012 one, however, categories have changed
% to bypass NLP and avoid problems agreed by TC.
%
% All extra explanations have been sent to corresponding appendix.
%
\subsection{Task}

\begin{enumerate}
	\item \textbf{Entering and command retrieval:} The robot enters the arena and drives to a designated position where it has to wait for further commands.

	\item \textbf{Command generation:} A command is generated randomly, depending on the command category chosen by the team (see below). Commands are generated by the generator which is made publicly available at https://github.com/kyordhel/GPSRCmdGen. \\

	\item \textbf{Command categories:} The team may choose from the following three categories:
	\begin{enumerate}
		\item \textbf{Category I:} Tasks with a low difficulty degree.
		\item \textbf{Category II:} Tasks with a moderate difficulty degree.
		\item \textbf{Category III:} Tasks with a high difficulty degree or with incomplete/erroneous information.
	\end{enumerate}

	\item \textbf{Task assignment:} The robot is given the command by the operator and may directly start to work on the task assignment.

	\item \textbf{Returning to the operator:} After accomplishing the assigned task, the robot has to move back to the operator to retrieve the next command (i.e., go back to 1. without the need of re-entering the arena). The robot can work on at most three commands. After the third command, it has to leave the arena.

	\item \textbf{Exiting the arena:} After accomplishing the assigned task, the robot has to leave the arena.

	The robot must prove it has understood the given command by repeating it (Please see the remarks about this in section~\ref{sec:gpsr_remarks}).
\end{enumerate}

\subsection{Additional rules and remarks}
\label{sec:gpsr_remarks}
\begin{enumerate}
	\item \textbf{Referees:} Since the score system in this test involves a subjective evaluation of the robot's behavior, the referees are EC/TC members.

	\item \textbf{Category selection:} For every of the three commands given to the robot, the team chooses the desired command category.

	\item \textbf{Operator:}
	\begin{itemize}
		\item The person operating the robot is one of the referees (default operator).
		\item If the robot appears to consistently not be able to understand the operator, the referees ask the team to use a custom operator or bypassing speech recognition (\refsec{rule:asrcontinue}).
	\end{itemize}

	\item \textbf{Retrieving the command:} The robot must show it has understood the given command by repeating the command (i.e.~stating all the required information to accomplish the task).
	\\
	\textit{Note:} Referees must have sufficient evidence proving the robot is actively trying to execute the commanded tasks to score. Robots skipping command execution will not receive points for understanding the command.

	\item \textbf{Incremental scoring:} Scoring depends on the category chosen by the team leader and the previous successfully accomplished command. Thereby, scoring for a second and third command depends on how well the robot solved (not understood) a first and second command respectively. Referees determine how well the command was accomplished and its impact on the incremental scoring of subsequent commands.
\end{enumerate}

\subsection{Referee and OC instructions}
\textbf{2h before test:}
\begin{itemize}
	\item Specify and announce the entrance and exit door
	\item Specify and announce the command retrieval point
\end{itemize}

\subsection {Audio Data Recollection}
Teams are encouraged to submit to the TC the audio data recorded during the test, specially that which was captured during speech recoginition. If so, teams are urged to provide it with annotation of what the user said and what was recognized. Audio files are expected to be mono, one per microphone (in the case array recordings), of a sample rate equal to or higher than 16 kHz, and with a sample size of at least 16 bits. Depending on the quality of the recordings and their annothations, an official certificate that formalizes these efforts may be provided to submitting teams.

\newpage
\subsection{Score sheet}
\input{scoresheets/GPSR.tex}

% Local Variables:
% TeX-master: "Rulebook"
% End:
